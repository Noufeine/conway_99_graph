{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noufeine/conway_99_graph/blob/main/2_renforcement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM3l9MxHsJ5L"
      },
      "outputs": [],
      "source": [
        "# Code to accompany the paper \"Constructions in combinatorics via neural networks and LP solvers\" by A Z Wagner\n",
        "# Code for conjecture 2.1, without the use of numba \n",
        "#\n",
        "# Please keep in mind that I am far from being an expert in reinforcement learning. \n",
        "# If you know what you are doing, you might be better off writing your own code.\n",
        "#\n",
        "# This code works on tensorflow version 1.14.0 and python version 3.6.3\n",
        "# It mysteriously breaks on other versions of python.\n",
        "# For later versions of tensorflow there seems to be a massive overhead in the predict function for some reason, and/or it produces mysterious errors.\n",
        "# Debugging these was way above my skill level.\n",
        "# If the code doesn't work, make sure you are using these versions of tf and python.\n",
        "#\n",
        "# I used keras version 2.3.1, not sure if this is important, but I recommend this just to be safe.\n",
        "\n",
        "\n",
        "\n",
        "import networkx as nx #for various graph parameters, such as eigenvalues, macthing number, etc\n",
        "import random\n",
        "import numpy as np\n",
        "#from keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "#from keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from keras.models import load_model\n",
        "from statistics import mean\n",
        "import pickle\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "import os, psutil\n",
        "process = psutil.Process(os.getpid())\n",
        "#9, 4, 1, 2\n",
        "\n",
        "N = 16   #number of vertices in the graph. Only used in the reward function, not directly relevant to the algorithm \n",
        "MYN = int(N*(N-1)/2)  #The length of the word we are generating. Here we are generating a graph, so we create a 0-1 word of length (N choose 2)\n",
        "\n",
        "LEARNING_RATE = 0.0001 #Increase this to make convergence faster, decrease if the algorithm gets stuck in local optima too often.\n",
        "n_sessions =100 #number of new sessions per iteration\n",
        "percentile = 93 #top 100-X percentile we are learning from\n",
        "super_percentile = 94 #top 100-X percentile that survives to next iteration\n",
        "\n",
        "FIRST_LAYER_NEURONS = 128 #Number of neurons in the hidden layers.\n",
        "SECOND_LAYER_NEURONS = 64\n",
        "THIRD_LAYER_NEURONS = 4\n",
        "\n",
        "n_actions = 2 #The size of the alphabet. In this file we will assume this is 2. There are a few things we need to change when the alphabet size is larger,\n",
        "\t\t\t  #such as one-hot encoding the input, and using categorical_crossentropy as a loss function.\n",
        "\t\t\t  \n",
        "observation_space = 2*MYN #Leave this at 2*MYN. The input vector will have size 2*MYN, where the first MYN letters encode our partial word (with zeros on\n",
        "\t\t\t\t\t\t  #the positions we haven't considered yet), and the next MYN bits one-hot encode which letter we are considering now.\n",
        "\t\t\t\t\t\t  #So e.g. [0,1,0,0,   0,0,1,0] means we have the partial word 01 and we are considering the third letter now.\n",
        "\t\t\t\t\t\t  #Is there a better way to format the input to make it easier for the neural network to understand things?\n",
        "\n",
        "\t\t\t\t\t\t  \n",
        "len_game = MYN \n",
        "state_dim = (observation_space,)\n",
        "\n",
        "INF = 1000000\n",
        "\n",
        "\n",
        "#Model structure: a sequential network with three hidden layers, sigmoid activation in the output.\n",
        "#I usually used relu activation in the hidden layers but play around to see what activation function and what optimizer works best.\n",
        "#It is important that the loss is binary cross-entropy if alphabet size is 2.\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(FIRST_LAYER_NEURONS,  activation=\"relu\"))\n",
        "model.add(Dense(SECOND_LAYER_NEURONS, activation=\"relu\"))\n",
        "model.add(Dense(THIRD_LAYER_NEURONS, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.build((None, observation_space))\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=SGD(learning_rate = LEARNING_RATE)) #Adam optimizer also works well, with lower learning rate\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "#renvoie le degree d'un sommet\n",
        "def get_degree(matrice, sommet):\n",
        "  degree = 0\n",
        "  for i in range(len(matrice[sommet])):\n",
        "    degree+=matrice[sommet][i]\n",
        "  return degree\n",
        "\n",
        "#renvoies tous les voisins d'un sommet excepté sauf\n",
        "def tous_les_voisins(matrice, sommet, sauf):\n",
        "  tous_voisins = []\n",
        "  for i in range(len(matrice[sommet])):\n",
        "    if(matrice[sommet][i] == 1 and i!=sauf):\n",
        "      tous_voisins.append(i)\n",
        "  return tous_voisins\n",
        "\n",
        "#renvoie le nombre de voisins en commun entre 2 sommets:\n",
        "def nbr_voisins_en_commun(matrice, sommet_1, sommet_2):\n",
        "  les_voisins_1 = tous_les_voisins(matrice, sommet_1, sommet_2)\n",
        "  les_voisins_2 = tous_les_voisins(matrice, sommet_2, sommet_1)\n",
        "  nbr_voisins = 0\n",
        "  for i in range( len(les_voisins_1) ):\n",
        "    if( les_voisins_1[i] in les_voisins_2 ): \n",
        "      nbr_voisins+=1\n",
        "  return nbr_voisins\n",
        "\n",
        "def calcScore(state):\n",
        "#Etape 1 : Définition des paramètres.\n",
        "  #le degre\n",
        "  degre = 6\n",
        "  #lambda : Toute paire de sommets adjacents a exactement λ voisins communs.\n",
        "  lambda_1 = 2\n",
        "  #mu : Toute paire de sommets non-adjacents a exactement μ voisins communs\n",
        "  mu = 2\n",
        "\n",
        "  #Etape 2 : construction de la matrice qui va nous servir à construire le graphe\n",
        "\t#and get_degree(matrice, i) < degre and get_degree(matrice, j) < degre and nbr_voisins_en_commun(matrice, i, j) <= lambda_1\n",
        "  matrice = np.zeros((N,N))\n",
        "  count = 0\n",
        "  for i in range(N):\n",
        "    for j in range(i+1, N):\n",
        "      if( state[count] == 1  ):\n",
        "        matrice[i][j] = 1\n",
        "        matrice[j][i] = 1\n",
        "      count += 1\n",
        "\n",
        "  #Etape 3 :création de la matrice des tests: si la matrice n'a que des 0, alors toutes les conditions ont été satisfaite.\n",
        "  #+calcul du score\n",
        "  matrice_test = np.zeros((N,N))\n",
        "  score = 0\n",
        "  vrs = 0\n",
        "  for i in range(N):\n",
        "    for j in range(N):\n",
        "      if( i == j and matrice[i][j] == 0 and get_degree(matrice, i) == degre and get_degree(matrice, j) == degre ):\n",
        "        matrice_test[i][j] = 1\n",
        "        score+= 0\n",
        "        vrs+=1\n",
        "      elif( matrice[i][j] == 1 and nbr_voisins_en_commun(matrice, i, j) == lambda_1 ):\n",
        "        matrice_test[i][j] = 1\n",
        "        score+= 0\n",
        "        vrs+=1\n",
        "      elif( matrice[i][j] == 0 and nbr_voisins_en_commun(matrice, i, j) == mu ):\n",
        "        matrice_test[i][j] = 1\n",
        "        score+= 0\n",
        "        vrs+=1\n",
        "      else:\n",
        "        matrice_test[i][j] = 0\n",
        "        score+= -1\n",
        "        vrs+=0\n",
        "  \n",
        "  #Etape 4 : construction du graphe.\n",
        "  G = nx.from_numpy_matrix(matrice) \n",
        "\n",
        "  #Etape 5 : renvoie du score et affichage du graphique pour un certains score\n",
        "  #G est supposé connexe. Si ce n'est pas le cas, renvoyez une récompense très négative.\n",
        "  if( not (nx.is_connected(G)) ):\n",
        "    return [-INF, vrs/(N*N)]\n",
        "\n",
        "  if( vrs/(N*N) == 1 ):\n",
        "    #print(score)\n",
        "    print(matrice_test)\n",
        "    print(matrice)\n",
        "    print(vrs/(N*N)*100)\n",
        "    nx.draw_circular(G, with_labels=True)\n",
        "    plt.show()\n",
        "    exit()\n",
        "  return [score, vrs/(N*N)]\n",
        "\n",
        "\n",
        "####No need to change anything below here. \n",
        "\t\n",
        "\t\n",
        "\t\t\t\t\t\t\n",
        "\n",
        "def generate_session(agent, n_sessions, verbose = 1):\n",
        "\t\"\"\"\n",
        "\tPlay n_session games using agent neural network.\n",
        "\tTerminate when games finish \n",
        "\t\n",
        "\tCode inspired by https://github.com/yandexdataschool/Practical_RL/blob/master/week01_intro/deep_crossentropy_method.ipynb\n",
        "\t\"\"\"\n",
        "\tstates =  np.zeros([n_sessions, observation_space, len_game], dtype=int)\n",
        "\tactions = np.zeros([n_sessions, len_game], dtype = int)\n",
        "\tstate_next = np.zeros([n_sessions,observation_space], dtype = int)\n",
        "\tprob = np.zeros(n_sessions)\n",
        "\tstates[:,MYN,0] = 1\n",
        "\tstep = 0\n",
        "\ttotal_score = np.zeros([n_sessions])\n",
        "\trecordsess_time = 0\n",
        "\tplay_time = 0\n",
        "\tscorecalc_time = 0\n",
        "\tpred_time = 0\n",
        "\tscore_tt = 0\n",
        "\tit = 0\n",
        "\twhile (True):\n",
        "\t\tstep += 1\t\t\n",
        "\t\ttic = time.time()\n",
        "\t\tprob = agent.predict(states[:,:,step-1], batch_size = n_sessions) \n",
        "\t\tpred_time += time.time()-tic\n",
        "\t\t\n",
        "\t\tfor i in range(n_sessions):\n",
        "\t\t\t\n",
        "\t\t\tif np.random.rand() < prob[i]:\n",
        "\t\t\t\taction = 1\n",
        "\t\t\telse:\n",
        "\t\t\t\taction = 0\n",
        "\t\t\tactions[i][step-1] = action\n",
        "\t\t\ttic = time.time()\n",
        "\t\t\tstate_next[i] = states[i,:,step-1]\n",
        "\t\t\tplay_time += time.time()-tic\n",
        "\t\t\tif (action > 0):\n",
        "\t\t\t\tstate_next[i][step-1] = action\t\t\n",
        "\t\t\tstate_next[i][MYN + step-1] = 0\n",
        "\t\t\tif (step < MYN):\n",
        "\t\t\t\tstate_next[i][MYN + step] = 1\t\t\t\n",
        "\t\t\tterminal = step == MYN\n",
        "\t\t\ttic = time.time()\n",
        "\t\t\tif terminal:\n",
        "\t\t\t\tit+=1\n",
        "\t\t\t\tscore_tt+=calcScore(state_next[i])[1]\n",
        "\t\t\t\ttotal_score[i] = calcScore(state_next[i])[0]\n",
        "\t\t\tscorecalc_time += time.time()-tic\n",
        "\t\t\ttic = time.time()\n",
        "\t\t\tif not terminal:\n",
        "\t\t\t\tstates[i,:,step] = state_next[i]\t\t\t\n",
        "\t\t\trecordsess_time += time.time()-tic\n",
        "\t\t\t\n",
        "\t\t\n",
        "\t\tif terminal:\n",
        "\t\t\tbreak\n",
        "\t#If you want, print out how much time each step has taken. This is useful to find the bottleneck in the program.\t\n",
        "\tif (1==1):\n",
        "\t\tprint(process.memory_info().rss) \n",
        "\t\t#print(score_tt/it)\n",
        "\t\t#print(\"Predict: \"+str(pred_time)+\", play: \" + str(play_time) +\", scorecalc: \" + str(scorecalc_time) +\", recordsess: \" + str(recordsess_time))\n",
        "\treturn states, actions, total_score\n",
        "\n",
        "\n",
        "\n",
        "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
        "\t\"\"\"\n",
        "\tSelect states and actions from games that have rewards >= percentile\n",
        "\t:param states_batch: list of lists of states, states_batch[session_i][t]\n",
        "\t:param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
        "\t:param rewards_batch: list of rewards, rewards_batch[session_i]\n",
        "\t:returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
        "\t\n",
        "\tThis function was mostly taken from https://github.com/yandexdataschool/Practical_RL/blob/master/week01_intro/deep_crossentropy_method.ipynb\n",
        "\tIf this function is the bottleneck, it can easily be sped up using numba\n",
        "\t\"\"\"\n",
        "\tcounter = n_sessions * (100.0 - percentile) / 100.0\n",
        "\treward_threshold = np.percentile(rewards_batch,percentile)\n",
        "\n",
        "\telite_states = []\n",
        "\telite_actions = []\n",
        "\telite_rewards = []\n",
        "\tfor i in range(len(states_batch)):\n",
        "\t\tif rewards_batch[i] >= reward_threshold-0.0000001:\t\t\n",
        "\t\t\tif (counter > 0) or (rewards_batch[i] >= reward_threshold+0.0000001):\n",
        "\t\t\t\tfor item in states_batch[i]:\n",
        "\t\t\t\t\telite_states.append(item.tolist())\n",
        "\t\t\t\tfor item in actions_batch[i]:\n",
        "\t\t\t\t\telite_actions.append(item)\t\t\t\n",
        "\t\t\tcounter -= 1\n",
        "\telite_states = np.array(elite_states, dtype = int)\t\n",
        "\telite_actions = np.array(elite_actions, dtype = int)\t\n",
        "\treturn elite_states, elite_actions\n",
        "\t\n",
        "def select_super_sessions(states_batch, actions_batch, rewards_batch, percentile=90):\n",
        "\t\"\"\"\n",
        "\tSelect all the sessions that will survive to the next generation\n",
        "\tSimilar to select_elites function\n",
        "\tIf this function is the bottleneck, it can easily be sped up using numba\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tcounter = n_sessions * (100.0 - percentile) / 100.0\n",
        "\treward_threshold = np.percentile(rewards_batch,percentile)\n",
        "\n",
        "\tsuper_states = []\n",
        "\tsuper_actions = []\n",
        "\tsuper_rewards = []\n",
        "\tfor i in range(len(states_batch)):\n",
        "\t\tif rewards_batch[i] >= reward_threshold-0.0000001:\n",
        "\t\t\tif (counter > 0) or (rewards_batch[i] >= reward_threshold+0.0000001):\n",
        "\t\t\t\tsuper_states.append(states_batch[i])\n",
        "\t\t\t\tsuper_actions.append(actions_batch[i])\n",
        "\t\t\t\tsuper_rewards.append(rewards_batch[i])\n",
        "\t\t\t\tcounter -= 1\n",
        "\tsuper_states = np.array(super_states, dtype = int)\n",
        "\tsuper_actions = np.array(super_actions, dtype = int)\n",
        "\tsuper_rewards = np.array(super_rewards)\n",
        "\treturn super_states, super_actions, super_rewards\n",
        "\t\n",
        "\n",
        "super_states =  np.empty((0,len_game,observation_space), dtype = int)\n",
        "super_actions = np.array([], dtype = int)\n",
        "super_rewards = np.array([])\n",
        "sessgen_time = 0\n",
        "fit_time = 0\n",
        "score_time = 0\n",
        "#nombre de génération à créer.\n",
        "nbr_generation = 1000000\n",
        "myRandon = 50\n",
        "\n",
        "\n",
        "myRand = random.randint(0,1000) #used in the filename\n",
        "\n",
        "for i in range(nbr_generation): #1000000 generations should be plenty\n",
        "\t#generate new sessions\n",
        "\t#performance can be improved with joblib\n",
        "\ttic = time.time()\n",
        "\tsessions = generate_session(model,n_sessions,0) #change 0 to 1 to print out how much time each step in generate_session takes \n",
        "\tsessgen_time = time.time()-tic\n",
        "\ttic = time.time()\n",
        "\t\n",
        "\tstates_batch = np.array(sessions[0], dtype = int)\n",
        "\tactions_batch = np.array(sessions[1], dtype = int)\n",
        "\trewards_batch = np.array(sessions[2])\n",
        "\tstates_batch = np.transpose(states_batch,axes=[0,2,1])\n",
        "\t\n",
        "\tstates_batch = np.append(states_batch,super_states,axis=0)\n",
        "\n",
        "\tif i>0:\n",
        "\t\tactions_batch = np.append(actions_batch,np.array(super_actions),axis=0)\t\n",
        "\trewards_batch = np.append(rewards_batch,super_rewards)\n",
        "\t\t\n",
        "\trandomcomp_time = time.time()-tic \n",
        "\ttic = time.time()\n",
        "\n",
        "\telite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile=percentile) #pick the sessions to learn from\n",
        "\tselect1_time = time.time()-tic\n",
        "\n",
        "\ttic = time.time()\n",
        "\tsuper_sessions = select_super_sessions(states_batch, actions_batch, rewards_batch, percentile=super_percentile) #pick the sessions to survive\n",
        "\tselect2_time = time.time()-tic\n",
        "\t\n",
        "\ttic = time.time()\n",
        "\tsuper_sessions = [(super_sessions[0][i], super_sessions[1][i], super_sessions[2][i]) for i in range(len(super_sessions[2]))]\n",
        "\tsuper_sessions.sort(key=lambda super_sessions: super_sessions[2],reverse=True)\n",
        "\tselect3_time = time.time()-tic\n",
        "\t\n",
        "\ttic = time.time()\n",
        "\tmodel.fit(elite_states, elite_actions) #learn from the elite sessions\n",
        "\tfit_time = time.time()-tic\n",
        "\t\n",
        "\ttic = time.time()\n",
        "\t\n",
        "\tsuper_states = [super_sessions[i][0] for i in range(len(super_sessions))]\n",
        "\tsuper_actions = [super_sessions[i][1] for i in range(len(super_sessions))]\n",
        "\tsuper_rewards = [super_sessions[i][2] for i in range(len(super_sessions))]\n",
        "\t\n",
        "\trewards_batch.sort()\n",
        "\tmean_all_reward = np.mean(rewards_batch[-100:])\t\n",
        "\tmean_best_reward = np.mean(super_rewards)\t\n",
        "\n",
        "\tscore_time = time.time()-tic\n",
        "\t\n",
        "  #affichage des meilleurs individus et de leurs scores\n",
        "\t#print(\"\\n\" + str(i) +  \". Best individuals: \" + str(np.flip(np.sort(super_rewards))))\n",
        "\t\n",
        "\t#uncomment below line to print out how much time each step in this loop takes. \n",
        "  #affichage de la moyenne des individus\n",
        "\t#print(\t\"Mean reward: \" + str(mean_all_reward) + \"\\nSessgen: \" + str(sessgen_time) + \", other: \" + str(randomcomp_time) + \", select1: \" + str(select1_time) + \", select2: \" + str(select2_time) + \", select3: \" + str(select3_time) +  \", fit: \" + str(fit_time) + \", score: \" + str(score_time)) \n",
        "\t\n",
        "\t\"\"\"\n",
        "\tif (i%20 == 1): #Write all important info to files every 20 iterations\n",
        "\t\twith open('best_species_pickle_'+str(myRand)+'.txt', 'wb') as fp:\n",
        "\t\t\tpickle.dump(super_actions, fp)\n",
        "\t\twith open('best_species_txt_'+str(myRand)+'.txt', 'w') as f:\n",
        "\t\t\tfor item in super_actions:\n",
        "\t\t\t\tf.write(str(item))\n",
        "\t\t\t\tf.write(\"\\n\")\n",
        "\t\twith open('best_species_rewards_'+str(myRand)+'.txt', 'w') as f:\n",
        "\t\t\tfor item in super_rewards:\n",
        "\t\t\t\tf.write(str(item))\n",
        "\t\t\t\tf.write(\"\\n\")\n",
        "\t\twith open('best_100_rewards_'+str(myRand)+'.txt', 'a') as f:\n",
        "\t\t\tf.write(str(mean_all_reward)+\"\\n\")\n",
        "\t\twith open('best_elite_rewards_'+str(myRand)+'.txt', 'a') as f:\n",
        "\t\t\tf.write(str(mean_best_reward)+\"\\n\")\n",
        "\tif (i%200==2): # To create a timeline, like in Figure 3\n",
        "\t\twith open('best_species_timeline_txt_'+str(myRand)+'.txt', 'a') as f:\n",
        "\t\t\tf.write(str(super_actions[0]))\n",
        "\t\t\tf.write(\"\\n\")\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "2-renforcement.ipynb",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMEJ3yYm1IChsPAY9/+ZA+s",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}